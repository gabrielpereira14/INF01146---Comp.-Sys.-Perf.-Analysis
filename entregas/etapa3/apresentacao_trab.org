#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+PROPERTY: header-args :python :var ORGDIR=(file-name-directory buffer-file-name) :exports results  

#+TITLE: Medição do impacto de uma infraestrutura de VPN na taxa de transmissão e na latência
#+AUTHOR: Ester Crestani, Gabriel Pereira e Júlia Pimentel
#+DATE: 30/11/2025
#+OPTIONS: eval

* Medição do impacto da infraestrutura de VPN da UFRGS na taxa de transmissão e na latência :noexport:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:

  O objetivo deste trabalho é avaliar o impacto da infraestrutura de VPN da UFRGS, utilizada através do OpenVPN, sobre o throughput, latência, jitter e perda de pacotes.

** Ferramentas utilizadas 
  - iperf para a coleta de throughput;
  - ping para a coleta de latência, jitter e perda de pacotes.

** Metodologia 
  Foram desenvolvidos dois scripts para a coleta de dados. O principal é o run_test.py, ele contém as funções que iniciam e param a execução da VPN, além de 
  chamar o script que faz os experimentos do ping. Também contém as funções para a execução dos testes do iperf. Tentou-se separar a parte do iperf em um terceiro script para
  manter uma melhor modularização, entretanto 
  - Execução simultânea de ping e iperf;
    
** Coleta dos dados 
  Para fazer a coleta dos dados, foram feitos 3 scripts:
    - "run_test.py" - é o script principal, é responsável pelo controle da VPN, bem como usa o script que coleta os dados do ping e coleta dados do ipef.
    - "run_ping_test.py" - coleta os dados do ping, foi feito em um outro arquivo para possibilitar a paralelização da coleta. 
    - "utils/env_loader" - le os dados do arquivo .env que define o nome da pasta onde salvar os dados coletados
    - "utils/csv_gzip_manager.py" - define as funcões que tratam de ler descompactar e compactar os dados no inicio e fim da coleta 
  
**** Como executar

***** Configuração do ambiente
  Garanta que as bibliotecas python necessárias estão instaladas, elas estão descritas no arquivo "requirements.txt" no diretório src, e podem ser facilmente instaladas com o comando:

`pip install -r requirements.txt`

  onde 'path' é o caminho para o arquivo "requirements.txt".

  Também é necessário criar um arquivo .env na raiz do projeto, ela deve conter a váriavel USER_NAME, por exemplo:
 
  `USER_NAME=meu_nome`

  com isso, os dados da coleta serão salvos em data/meu_nome.

  Por fim, também é necessario criar um arquivo chamado "pass.txt" no diretorio utils, este será o arquivo que conterá as suas credenciais de acesso à VPN da UFRGS (mesmas credenciais do moodle), neste formato:
   
  ```
  00112233
  minhasenhadomoodle
  ```

  Também é necessario executar o servidor do iperf no PCAD, usando: 

  ```
  iperf -s -p 8787
  ```

***** Executando a coleta
  Como o OpenVPN precisa ser rodado com sudo, para o nosso grupo foi mais fácil rodar o script de coleta diretamente pelo terminal do que usando o emacs. Dessa forma,
  deixaremos o conteudo dos scripts neste arquivo e o comando necessário para executá-los no terminal do sistema operacional.

  #+BEGIN_SRC python :exports :results output
    import os
    SCRIPT_DIR = ORGDIR 
    PROJECT_ROOT = os.path.abspath(os.path.join(SCRIPT_DIR, "..", ".."))

    print(f"python3 {PROJECT_ROOT}/src/run_tests.py")
  #+END_SRC

  #+RESULTS:
  : python3 /home/gabip/perf/src/run_tests.py

  Com esse comando é possível executar o script de coleta a partir do terminal

  A seguir estarão os scripts usados na coleta.

***** Script principal - run_tests.py
# `C-c '`  abre o conteudo em outro buffer de forma editavel
#+INCLUDE: "../../src/run_tests.py" src python
***** Script responsavel pelo ping - run_ping_test.py
# `C-c '`  abre o conteudo em outro buffer de forma editavel
#+INCLUDE: "../../src/run_ping_test.py" src python
***** Scripts que define as funcões que leem o env - env_loader.py
# `C-c '`  abre o conteudo em outro buffer de forma editavel
#+INCLUDE: "../../src/utils/env_loader.py" src python
***** Scripts que define as funcões que gerenciam a compressão dos dados coletados - env_loader.py
# `C-c '`  abre o conteudo em outro buffer de forma editavel
#+INCLUDE: "../../src/utils/csv_gzip_manager.py" src python
  
** Funcoes para plotar os graficos
Como alguns gráficos serão usados em mais de um lugar mas com a fonte dos dados diferente, deixaremos esses gráficos encapsulados em funcoes que permitem o facil reuso.

*** Setup

Bloco que importa as biblioteca necessárias e define as funcoes de importacao dos dados

#+BEGIN_SRC python :eval yes :exports :results output :session graphs
  import sys
  import pandas as pd
  import os
  import matplotlib.pyplot as plt
  import matplotlib.dates as mdates
  import seaborn as sns
  import gzip
  from scipy.stats import norm

  SCRIPT_DIR = ORGDIR 
  PROJECT_ROOT = os.path.abspath(os.path.join(SCRIPT_DIR, "..", ".."))
  DATA_ROOT = os.path.join(PROJECT_ROOT, "data")
  DATE_FMT = mdates.DateFormatter("%d/%m")


  def _load_csv_or_gzip(path: str):
      gz_path = path + ".gz"

      if os.path.exists(gz_path):
          with gzip.open(gz_path, "rt", encoding="utf-8") as f:
              return pd.read_csv(f)
      elif os.path.exists(path):
          return pd.read_csv(path)
      else:
          raise FileNotFoundError(f"No CSV or GZIP found for: {path}")

  def load_ping_data(user):
      csv = f"{DATA_ROOT}/{user}/ping_results.csv"
      df = _load_csv_or_gzip(csv)
      df["timestamp"] = pd.to_datetime(
          df["timestamp"],
          format="ISO8601",
          errors="raise"
      )
      return df

  def load_iperf_data(user):
      csv = f"{DATA_ROOT}/{user}/iperf_results.csv"
      df = _load_csv_or_gzip(csv)
      df["timestamp"] = pd.to_datetime(
          df["timestamp"],
          format="ISO8601",
          errors="raise"
      )
      return df

  def load_iperf_rev_data(user):
      csv = f"{DATA_ROOT}/{user}/iperf_results_reversed.csv"
      df = _load_csv_or_gzip(csv)
      df["timestamp"] = pd.to_datetime(
          df["timestamp"],
          format="ISO8601",
          errors="raise"
      )
      return df

  def ensure_img_dir(user):
      d = f"{PROJECT_ROOT}/data/{user}/images"
      os.makedirs(d, exist_ok=True)
      return d

  def last_value_per_session(df, column):
      df_sorted = df.sort_values("timestamp")
      return (
          df_sorted.groupby(["test_label", "session"])
          .tail(1)[["timestamp", "test_label", column]]
          .copy()
      )

  def label_line_end(ax, line, label=None, **kwargs):
      x, y = line.get_xdata(), line.get_ydata()
      label_text = label

      xmin, xmax = ax.get_xlim()
      xmax += (xmax - xmin) * 0.05
      ax.set_xlim(xmin, xmax)

      ax.text(
          x[-1],
          y[-1],
          f" {label_text}",
          color=line.get_color(),
          fontsize=10,
          va="center",
          ha="left",
          transform=ax.transData,
          ,**kwargs,
      )
#+END_SRC

#+RESULTS:

*** Jitter over time
#+NAME: plot_jitter_over_time
#+BEGIN_SRC python :var user="gabriel" :var image_size='(7 3) :var ci_level=0.95 :var combined_graph="true" :results file graphics :session graphs :exports both
    df = load_ping_data(user)
    img_dir = ensure_img_dir(user)

    df = last_value_per_session(df, "ping_jitter_ms")
    df = df[df["ping_jitter_ms"].notna()].copy()

    
    df["lb"] = df.groupby("test_label")["ping_jitter_ms"].transform(lambda x: x.quantile(0.01))
    df["ub"] = df.groupby("test_label")["ping_jitter_ms"].transform(lambda x: x.quantile(0.99))
    df = df[(df["ping_jitter_ms"] >= df["lb"]) & (df["ping_jitter_ms"] <= df["ub"])]
    df = df.drop(columns=["lb","ub"])

    df["timestamp"] = pd.to_datetime(df["timestamp"])
    df["hour"] = df["timestamp"].dt.floor("H")

    z = norm.ppf((1 + ci_level) / 2)

    hourly = (
        df.groupby(["test_label", "hour"])
        .agg(mean=("ping_jitter_ms","mean"),
             std=("ping_jitter_ms","std"),
             count=("ping_jitter_ms","count"))
        .reset_index()
    )

    hourly["stderr"] = hourly["std"] / hourly["count"].pow(0.5)
    hourly["ci"] = z * hourly["stderr"]

    labels = ["VPN_ON","VPN_OFF"]

    ci_label = f"ci{int(ci_level*100)}"

    if combined_graph:
        fig, ax = plt.subplots(figsize=image_size)
        axes = [ax]
    else:
        fig, axes = plt.subplots(1, 2, figsize=image_size)

    for i, label in enumerate(labels):
        ax = axes[0] if combined_graph else axes[i]
        
        subset = hourly[hourly["test_label"] == label].sort_values("hour")

        line, = ax.plot(subset["hour"], subset["mean"])
        ax.fill_between(
            subset["hour"],
            subset["mean"] - subset["ci"],
            subset["mean"] + subset["ci"],
            alpha=0.25,
            label=ci_label
            )

        ax.tick_params(axis='x', rotation=45)
        ax.xaxis.set_major_formatter(DATE_FMT)
        ax.xaxis.set_major_locator(mdates.DayLocator())
        ax.set_title(f"Jitter over time – {label}")
        ax.set_xlabel("Date")
        ax.set_ylabel("ms")
        ax.grid(alpha=0.3)
        ax.legend(loc="best", fontsize="small")
        label_line_end(ax, line, label)

    for ax in axes:
        ax.relim()
        ax.autoscale_view()
        ax.set_ylim(bottom=0)

    path = f"{img_dir}/jitter_over_time_{user}.png"
    plt.tight_layout()
    plt.savefig(path, dpi=150)
    plt.close()

    path
#+END_SRC

#+RESULTS: plot_jitter_over_time
[[file:/home/gabip/perf/data/gabriel/images/jitter_over_time_gabriel.png]]

*** Jitter per hour
#+NAME: plot_jitter_per_hour
#+BEGIN_SRC python :var user="gabriel" :var image_size='(7 3) :var ci_level=0.95 :var combined_graph="true" :results file graphics :session graphs :exports both
    df = load_ping_data(user)
    img_dir = ensure_img_dir(user)

    df = last_value_per_session(df, "ping_jitter_ms")

    df = df[df["ping_jitter_ms"].notna()].copy()
    df["lb"] = df.groupby("test_label")["ping_jitter_ms"].transform(lambda x: x.quantile(0.01))
    df["ub"] = df.groupby("test_label")["ping_jitter_ms"].transform(lambda x: x.quantile(0.99))
    df = df[(df["ping_jitter_ms"] >= df["lb"]) & (df["ping_jitter_ms"] <= df["ub"])]
    df = df.drop(columns=["lb","ub"])

    df["timestamp"] = pd.to_datetime(df["timestamp"])
    df["hour"] = df["timestamp"].dt.hour + 1

    z = norm.ppf((1 + ci_level) / 2)

    hourly = (
        df.groupby(["test_label", "hour"])
        .agg(mean=("ping_jitter_ms", "mean"),
                std=("ping_jitter_ms", "std"),
                count=("ping_jitter_ms", "count"))
        .reset_index()
    )

    hourly["stderr"] = hourly["std"] / hourly["count"].pow(0.5)
    hourly["ci"] = z * hourly["stderr"]

    labels = ["VPN_ON","VPN_OFF"]

    ci_label = f"ci{int(ci_level*100)}"

    if combined_graph:
        fig, ax = plt.subplots(figsize=image_size)
        axes = [ax]
    else:
        fig, axes = plt.subplots(1, 2, figsize=image_size)

    for i, label in enumerate(labels):
        ax = axes[0] if combined_graph else axes[i]
        
        subset = hourly[hourly["test_label"] == label].sort_values("hour")

        line, = ax.plot(subset["hour"], subset["mean"])
        ax.fill_between(
            subset["hour"],
            subset["mean"] - subset["ci"],
            subset["mean"] + subset["ci"],
            alpha=0.25, 
            label=ci_label
            )

        ax.set_title(f"Jitter per hour – {label}")
        ax.set_xlabel("Hour")
        ax.set_xticks(range(0,24,2))
        ax.grid(alpha=0.3)
        ax.set_xlim(1,24)
        if ax == axes[0]:
            ax.set_ylabel("ms")

        ax.legend(loc="best", fontsize="small")
        label_line_end(ax, line, label)

    for ax in axes:
        ax.relim()
        ax.autoscale_view()
        ax.set_ylim(bottom=0)

    path = f"{img_dir}/jitter_per_hour_{user}.png"
    plt.tight_layout()
    plt.savefig(path, dpi=150)
    plt.close()

    path
#+END_SRC

#+RESULTS: plot_jitter_per_hour
[[file:/home/gabip/perf/data/gabriel/images/jitter_per_hour_gabriel.png]]

#+RESULTS: plot_jitter
[[file:/home/gabip/perf/gabriel/images/jitter_gabriel.png]]


#+NAME: plot_latency_per_hour
#+BEGIN_SRC python :var user="gabriel" :var image_size='(9 3) :var ci_level=0.95 :var combined_graph="true" :results file graphics :session graphs :exports both
    import pandas as pd
    import matplotlib.pyplot as plt
    from scipy.stats import norm

    df = load_ping_data(user)
    img_dir = ensure_img_dir(user)

    df = df[df["ping_latency_ms"].notna()].copy()
    df["timestamp"] = pd.to_datetime(df["timestamp"])
    df["hour"] = df["timestamp"].dt.hour

    z = norm.ppf((1 + ci_level) / 2)

    hourly = (
        df.groupby(["test_label", "hour"])["ping_latency_ms"]
        .agg(["mean", "count", "std"])
        .reset_index()
    )

    hourly["stderr"] = hourly["std"] / hourly["count"].pow(0.5)
    hourly["ci"] = z * hourly["stderr"]

    labels = ["VPN_ON", "VPN_OFF"]

    ci_label = f"ci{int(ci_level*100)}"

    if combined_graph:
        fig, ax = plt.subplots(figsize=image_size)
        axes = [ax]
    else:
        fig, axes = plt.subplots(1, 2, figsize=image_size)

    for i, label in enumerate(labels):
        ax = axes[0] if combined_graph else axes[i]

        subset = hourly[hourly["test_label"] == label].sort_values("hour")

        line, = ax.plot(subset["hour"], subset["mean"])
        ax.fill_between(
            subset["hour"],
            subset["mean"] - subset["ci"],
            subset["mean"] + subset["ci"],
            alpha=0.25,
            label=ci_label
        )

        ax.set_title(f"Latency per hour of day – {label}")
        ax.set_xlabel("Hour of day")
        ax.set_ylabel("ms")
        ax.set_xticks(range(0, 24, 2))
        ax.grid(alpha=0.3)
        ax.set_xlim(0, 23)
        ax.legend(loc="best", fontsize="small")
        label_line_end(ax, line, label)

    for ax in axes:
        ax.relim()
        ax.autoscale_view()
        ax.set_ylim(bottom=0)

    path = f"{img_dir}/latency_per_hour_{user}.png"
    plt.tight_layout()
    plt.savefig(path, dpi=150)
    plt.close()

    path
#+END_SRC

*** Latencia ao longo do tempo
#+NAME: plot_latency_over_time
#+BEGIN_SRC python :var user="gabriel" :var image_size='(6 4) :var ci_level=0.95 :var combined_graph="true" :results file graphics :session graphs :exports both
    df = load_ping_data(user)
    img_dir = ensure_img_dir(user)

    df = df[df["ping_latency_ms"].notna()].copy()
    df["timestamp"] = pd.to_datetime(df["timestamp"])
    df["hour"] = df["timestamp"].dt.floor("H")

    z = norm.ppf((1 + ci_level) / 2)

    hourly = (
        df.groupby(["test_label", "hour"])
        .agg(
            mean=("ping_latency_ms", "mean"),
            std=("ping_latency_ms", "std"),   
            count=("ping_latency_ms", "count"),
        )
        .reset_index()
    )

    hourly["stderr"] = hourly["std"] / hourly["count"].pow(0.5)
    hourly["ci"] = z * hourly["stderr"]

    labels = ["VPN_ON", "VPN_OFF"]

    ci_label = f"ci{int(ci_level*100)}"

    if combined_graph:
        fig, ax = plt.subplots(figsize=image_size)
        axes = [ax]
    else:
        fig, axes = plt.subplots(1, 2, figsize=image_size)

    for i, label in enumerate(labels):
        ax = axes[0] if combined_graph else axes[i]

        subset = hourly[hourly["test_label"] == label].sort_values("hour")

        line, = ax.plot(subset["hour"], subset["mean"])
        ax.fill_between(
            subset["hour"],
            subset["mean"] - subset["ci"],
            subset["mean"] + subset["ci"],
            alpha=0.25,
            label=ci_label
        )

        ax.tick_params(axis='x', rotation=45)
        ax.xaxis.set_major_formatter(DATE_FMT)
        ax.xaxis.set_major_locator(mdates.DayLocator())
        ax.set_title(f"Latency per hour of day – {label}")
        ax.set_xlabel("Hour of day")
        ax.set_ylabel("ms")
        ax.grid(alpha=0.3)
        ax.legend(loc="best", fontsize="small")
        label_line_end(ax, line, label)

    for ax in axes:
        ax.relim()
        ax.autoscale_view()
        ax.set_ylim(bottom=0)

    path = f"{img_dir}/latency_over_time_{user}.png"
    plt.tight_layout()
    plt.savefig(path, dpi=150)
    plt.close()

    path
#+END_SRC

#+RESULTS: plot_latency_over_time
[[file:/home/gabip/perf/data/gabriel/images/latency_over_time_gabriel.png]]

*** Latencia por hora

#+NAME: plot_latency_per_hour
#+BEGIN_SRC python :var user="gabriel" :var image_size='(9 3) :var ci_level=0.95 :var combined_graph="true" :results file graphics :session graphs :exports both
    df = load_ping_data(user)
    img_dir = ensure_img_dir(user)

    df["lb"] = df.groupby("test_label")["ping_latency_ms"].transform(lambda x: x.quantile(0.01))
    df["ub"] = df.groupby("test_label")["ping_latency_ms"].transform(lambda x: x.quantile(0.99))
    df = df[(df["ping_latency_ms"] >= df["lb"]) & (df["ping_latency_ms"] <= df["ub"])]
    df = df.drop(columns=["lb", "ub"])

    df = df[df["ping_latency_ms"].notna()].copy()
    df["timestamp"] = pd.to_datetime(df["timestamp"])
    df["hour"] = df["timestamp"].dt.hour + 1

    z = norm.ppf((1 + ci_level) / 2)

    hourly = (
        df.groupby(["test_label", "hour"])
        .agg(
            mean=("ping_latency_ms", "mean"),
            std=("ping_latency_ms", "std"),   
            count=("ping_latency_ms", "count"),
        )
        .reset_index()
    )


    hourly["stderr"] = hourly["std"] / hourly["count"].pow(0.5)
    hourly["ci"] = z * hourly["stderr"]

    labels = ["VPN_ON", "VPN_OFF"]

    ci_label = f"ci{int(ci_level*100)}"

    if combined_graph:
        fig, ax = plt.subplots(figsize=image_size)
        axes = [ax]
    else:
        fig, axes = plt.subplots(1, 2, figsize=image_size)

    for i, label in enumerate(labels):
        ax = axes[0] if combined_graph else axes[i]
            
        subset = hourly[hourly["test_label"] == label].sort_values("hour")

        line, = ax.plot(subset["hour"], subset["mean"])
        ax.fill_between(
            subset["hour"],
            subset["mean"] - subset["ci"],
            subset["mean"] + subset["ci"],
            alpha=0.25,
            label=ci_label
        )

        ax.set_title(f"Latency per hour of day – {label}")
        ax.set_xlabel("Hour of day")
        ax.set_xticks(range(0, 24, 2))
        ax.grid(alpha=0.3)
        ax.set_xlim(1, 24)
        if ax == axes[0]:
            ax.set_ylabel("ms")
        ax.legend(loc="best", fontsize="small")
        label_line_end(ax, line, label)

    for ax in axes:
        ax.relim()
        ax.autoscale_view()
        ax.set_ylim(bottom=0)

    path = f"{img_dir}/latency_per_hour_{user}.png"
    plt.tight_layout()
    plt.savefig(path, dpi=150)
    plt.close()

    path
#+END_SRC

#+RESULTS: plot_latency_per_hour
[[file:/home/gabip/perf/data/gabriel/images/latency_per_hour_gabriel.png]]

*** Upload ao longo do tempo

#+NAME: plot_upload_over_time
#+BEGIN_SRC python :var user="gabriel" :var image_size='(9 3) :var ci_level=0.95 :var combined_graph="true" :results file graphics :session graphs :exports both
    df = load_iperf_data(user)
    img_dir = ensure_img_dir(user)

    df_t = df[df["tcp_throughput_mbps"].notna()].copy()
    df_t["timestamp"] = pd.to_datetime(df_t["timestamp"])
    df_t["hour"] = df_t["timestamp"].dt.floor("H")

    z = norm.ppf((1 + ci_level) / 2)

    hourly = (
        df_t.groupby(["test_label", "hour"])["tcp_throughput_mbps"]
        .agg(['mean', 'count', 'std'])
        .reset_index()
    )

    hourly["stderr"] = hourly["std"] / hourly["count"].pow(0.5)
    hourly["ci"] = z * hourly["stderr"]


    labels = ["VPN_ON", "VPN_OFF"]

    ci_label = f"ci{int(ci_level*100)}"

    if combined_graph:
        fig, ax = plt.subplots(figsize=image_size)
        axes = [ax]
    else:
        fig, axes = plt.subplots(1, 2, figsize=image_size)

    for i, label in enumerate(labels):
        ax = axes[0] if combined_graph else axes[i]

        subset = hourly[hourly["test_label"] == label]

        line, = ax.plot(subset["hour"], subset["mean"])
        ax.fill_between(
            subset["hour"],
            subset["mean"] - subset["ci"],
            subset["mean"] + subset["ci"],
            alpha=0.25,
            label=ci_label
        )
        ax.tick_params(axis='x', rotation=45)
        ax.xaxis.set_major_formatter(DATE_FMT)
        ax.xaxis.set_major_locator(mdates.DayLocator())
        ax.tick_params(axis='x', rotation=45)
        ax.set_xlabel("Date")
        ax.set_ylabel("Mbps")
        ax.set_title(f"Upload over time – {label}")
        ax.set_ylim(bottom = 0)
        ax.legend(loc="best", fontsize="small")
        label_line_end(ax, line, label)

    for ax in axes:
        ax.relim()
        ax.autoscale_view()
        ax.set_ylim(bottom=0)


    path = f"{img_dir}/upload_over_time_{user}.png"
    plt.tight_layout()
    plt.savefig(path, dpi=150)
    plt.close()

    path
#+END_SRC

#+RESULTS: plot_upload_over_time
[[file:/home/gabip/perf/data/gabriel/images/upload_over_time_gabriel.png]]

*** Download ao longo do tempo 

#+NAME: plot_download_over_time
#+BEGIN_SRC python :var user="gabriel" :var image_size='(9 3) :var ci_level=0.95 :var combined_graph="true" :results file graphics :session graphs :exports both
    df = load_iperf_rev_data(user)
    img_dir = ensure_img_dir(user)

    df_t = df[df["tcp_throughput_mbps"].notna()].copy()
    df_t["timestamp"] = pd.to_datetime(df_t["timestamp"])
    df_t["hour"] = df_t["timestamp"].dt.floor("H")

    z = norm.ppf((1 + ci_level) / 2)

    hourly = (
        df_t.groupby(["test_label", "hour"])["tcp_throughput_mbps"]
        .agg(['mean', 'count', 'std'])
        .reset_index()
    )

    hourly["stderr"] = hourly["std"] / hourly["count"].pow(0.5)
    hourly["ci"] = z * hourly["stderr"]


    labels = ["VPN_ON", "VPN_OFF"]

    ci_label = f"ci{int(ci_level*100)}"

    if combined_graph:
        fig, ax = plt.subplots(figsize=image_size)
        axes = [ax]
    else:
        fig, axes = plt.subplots(1, 2, figsize=image_size)

    for i, label in enumerate(labels):
        ax = axes[0] if combined_graph else axes[i]

        subset = hourly[hourly["test_label"] == label]

        line, = ax.plot(subset["hour"], subset["mean"])
        ax.fill_between(
            subset["hour"],
            subset["mean"] - subset["ci"],
            subset["mean"] + subset["ci"],
            alpha=0.25,
            label=ci_label
        )
        ax.tick_params(axis='x', rotation=45)
        ax.xaxis.set_major_formatter(DATE_FMT)
        ax.xaxis.set_major_locator(mdates.DayLocator())
        ax.tick_params(axis='x', rotation=45)
        ax.set_xlabel("Date")
        ax.set_ylabel("Mbps")
        ax.set_title(f"Download over time  – {label}")
        ax.legend(loc="best", fontsize="small")
        label_line_end(ax, line, label)

    for ax in axes:
        ax.relim()
        ax.autoscale_view()
        ax.set_ylim(bottom=0)

    path = f"{img_dir}/download_over_time_{user}.png"
    plt.tight_layout()
    plt.savefig(path, dpi=150)
    plt.close()

    path
#+END_SRC

#+RESULTS: plot_download_over_time
[[file:/home/gabip/perf/data/gabriel/images/download_over_time_gabriel.png]]

*** Upload por hora do dia  

#+NAME: plot_upload_per_hour
#+BEGIN_SRC python :var user="gabriel" :var image_size='(9 3) :var ci_level=0.95 :var combined_graph="true" :results file graphics :session graphs :exports both
    df = load_iperf_data(user)
    img_dir = ensure_img_dir(user)

    df = df[df["tcp_throughput_mbps"].notna()].copy()
    df["timestamp"] = pd.to_datetime(df["timestamp"])
    df["hour"] = df["timestamp"].dt.hour   

    z = norm.ppf((1 + ci_level) / 2)

    hourly = (
        df.groupby(["test_label", "hour"])["tcp_throughput_mbps"]
        .agg(["mean", "count", "std"])
        .reset_index()
    )

    hourly["stderr"] = hourly["std"] / hourly["count"].pow(0.5)
    hourly["ci"] = z * hourly["stderr"]

    labels = ["VPN_ON", "VPN_OFF"]
    
    ci_label = f"ci{int(ci_level*100)}"

    if combined_graph:
        fig, ax = plt.subplots(figsize=image_size)
        axes = [ax]
    else:
        fig, axes = plt.subplots(1, 2, figsize=image_size)

    for i, label in enumerate(labels):
        ax = axes[0] if combined_graph else axes[i]

        subset = hourly[hourly["test_label"] == label].sort_values("hour")

        line, = ax.plot(subset["hour"], subset["mean"])
        ax.fill_between(
            subset["hour"],
            subset["mean"] - subset["ci"],
            subset["mean"] + subset["ci"],
            alpha=0.25,
            label=ci_label
        )
        
        ax.set_title(f"Upload per hour of day – {label}")
        ax.set_xlabel("Hour of day")
        ax.set_ylabel("Mbps")
        ax.set_xticks(range(0, 24, 2))
        ax.set_xlim(1, 24)
        ax.grid(alpha=0.3)
        ax.legend(loc="best", fontsize="small")
        label_line_end(ax, line, label)

    for ax in axes:
        ax.relim()
        ax.autoscale_view()
        ax.set_ylim(bottom=0)

    path = f"{img_dir}/upload_per_hour_{user}.png"
    plt.tight_layout()
    plt.savefig(path, dpi=150)
    plt.close()

    path
#+END_SRC

#+RESULTS: plot_upload_per_hour
[[file:/home/gabip/perf/data/gabriel/images/upload_per_hour_gabriel.png]]

*** Download por hora do dia  

#+NAME: plot_download_per_hour
#+BEGIN_SRC python :var user="gabriel" :var image_size='(9 3) :var ci_level=0.95 :var combined_graph="true" :results file graphics :session graphs :exports both
    df = load_iperf_rev_data(user)
    img_dir = ensure_img_dir(user)

    df = df[df["tcp_throughput_mbps"].notna()].copy()
    df["timestamp"] = pd.to_datetime(df["timestamp"])
    df["hour"] = df["timestamp"].dt.hour + 1

    z = norm.ppf((1 + ci_level) / 2)

    hourly = (
        df.groupby(["test_label", "hour"])["tcp_throughput_mbps"]
        .agg(["mean", "count", "std"])
        .reset_index()
    )

    hourly["stderr"] = hourly["std"] / hourly["count"].pow(0.5)
    hourly["ci"] = z * hourly["stderr"]

    labels = ["VPN_ON", "VPN_OFF"]
    
    ci_label = f"ci{int(ci_level*100)}"

    if combined_graph:
        fig, ax = plt.subplots(figsize=image_size)
        axes = [ax]
    else:
        fig, axes = plt.subplots(1, 2, figsize=image_size)

    for i, label in enumerate(labels):
        ax = axes[0] if combined_graph else axes[i]

        subset = hourly[hourly["test_label"] == label].sort_values("hour")

        line, = ax.plot(subset["hour"], subset["mean"])
        ax.fill_between(
            subset["hour"],
            subset["mean"] - subset["ci"],
            subset["mean"] + subset["ci"],
            alpha=0.25,
            label=ci_label
        )

        ax.set_title(f"Download per hour of day – {label}")
        ax.set_xlabel("Hour of day")
        ax.set_ylabel("Mbps")
        ax.set_xticks(range(0, 24, 2))
        ax.grid(alpha=0.3)
        ax.set_xlim(1, 24)
        ax.legend(loc="best", fontsize="small")
        label_line_end(ax, line, label)

    for ax in axes:
        ax.relim()
        ax.autoscale_view()
        ax.set_ylim(bottom=0)

    path = f"{img_dir}/download_per_hour_{user}.png"
    plt.tight_layout()
    plt.savefig(path, dpi=150)
    plt.close()

    path
#+END_SRC

#+RESULTS: plot_download_per_hour
[[file:/home/gabip/perf/data/gabriel/images/download_per_hour_gabriel.png]]


** Regressão linear
    Apesar de dos dados serem series temporais, e o framework visto em aula não suportar esse tipo de análise, vamos aplicá-lo como forma de exercício.

    #+CALL: plot_latency_per_hour(user="gabriel") :session graphs
    
    #+RESULTS:
    [[file:/home/gabip/perf/data/gabriel/images/latency_per_hour_gabriel.png]]

    Vamos tenta explicar a latência em funcão da VPN estar ligada ou não.
    
    #+BEGIN_SRC python :exports :results output :session graphs
      import statsmodels.formula.api as smf

      df = load_ping_data("gabriel")

      print(df.head())

      reg = smf.ols("ping_latency_ms ~ test_label", data=df).fit()
      print(reg.summary())
  #+END_SRC

  #+RESULTS:
  #+begin_example
                     timestamp  session test_label  ping_latency_ms  ping_jitter_ms  ping_loss_%
  0 2025-11-12 22:19:59.276110        1     VPN_ON             15.1            0.00          0.0
  1 2025-11-12 22:20:00.252454        1     VPN_ON             10.6            0.28          0.0
  2 2025-11-12 22:20:01.252663        1     VPN_ON             11.0            0.29          0.0
  3 2025-11-12 22:20:02.261960        1     VPN_ON             20.8            0.88          0.0
  4 2025-11-12 22:20:03.251324        1     VPN_ON             11.8            1.39          0.0
                              OLS Regression Results                            
  ==============================================================================
  Dep. Variable:        ping_latency_ms   R-squared:                       0.030
  Model:                            OLS   Adj. R-squared:                  0.030
  Method:                 Least Squares   F-statistic:                 1.754e+04
  Date:                Sun, 30 Nov 2025   Prob (F-statistic):               0.00
  Time:                        17:26:21   Log-Likelihood:            -3.5501e+06
  No. Observations:              571302   AIC:                         7.100e+06
  Df Residuals:                  571300   BIC:                         7.100e+06
  Df Model:                           1                                         
  Covariance Type:            nonrobust                                         
  ========================================================================================
                             coef    std err          t      P>|t|      [0.025      0.975]
  ----------------------------------------------------------------------------------------
  Intercept               91.5325      0.228    402.024      0.000      91.086      91.979
  test_label[T.VPN_ON]   -42.3784      0.320   -132.433      0.000     -43.006     -41.751
  ==============================================================================
  Omnibus:                   736217.749   Durbin-Watson:                   0.666
  Prob(Omnibus):                  0.000   Jarque-Bera (JB):        492757964.398
  Skew:                           6.700   Prob(JB):                         0.00
  Kurtosis:                     146.251   Cond. No.                         2.63
  ==============================================================================

  Notes:
  [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
  #+end_example

  Obviamente a latência não é explicada pela VPN estar sendo usada ou não, podemos ver pelo R-squared, 0.030.

  Mas esse é um exemplo de como poderíamos fazer a análise caso fosse aplicável ao nosso trabalho.
  
* Apresentacao
:PROPERTIES:
:EXPORT_FILE_NAME: apresentacao
:BEAMER_env: ignoreheading
:EXPORT_LATEX_CLASS: beamer
:END:

#+OPTIONS: toc:nil
#+LATEX_CLASS: beamer
#+LATEX_HEADER: \setbeamertemplate{itemize item}{\textbullet}
#+LATEX_HEADER: \setbeamertemplate{itemize subitem}{\textbullet}
#+LATEX_HEADER: \setbeamertemplate{itemize subsubitem}{\textbullet}
#+LATEX_HEADER: \setbeamertemplate{headline}{}
#+LATEX_HEADER: \setbeamertemplate{footline}{}
#+LATEX_HEADER: \setbeamertemplate{navigation symbols}{}


** Objetivos do trabalho 
- Avaliar o impacto da infraestrutura de VPN da UFRGS

** Metodologia
Execução simultânea de ping e iperf através de um script que alterna entre:
    - Teste com a conexão via OpenVPN UFRGS.
    - Teste com conexão direta.

** Dados coletados
- Coleta automática de: latência, jitter, perda de pacotes (ping), throughput TCP e UDP (iperf3)
- Dados coletados por integrante do grupo, disponiveis dentro da pasta data
- Arquivos: 
    - =ping_results.csv=
    - =iperf_results.csv=
    - =iperf_results_reversed.csv=

** Ambiente de testes
- Servidor iperf: pcad.inf.ufrgs.br
- Site para ping: moodle.ufrgs.br

Autenticação automática via arquivo pass.txt
Intervalos entre testes: 5 segundos
Duração de cada medição: 10 segundos

- Testes realizados em diferentes dias e horários para melhor amostragem

** Material para medição
# Adicionar Script em python utilizado para solicitar as medidas #

** Resultados preliminares:
- Gráficos

** Próximos passos:
- Realizar mais medições em diferentes horários
- Gerar novas análises e indicadoresP
- Preparar análise crítica para etapa final

** Slide 3 exemplo para imagem

#+CALL: plot_latency_per_hour(user="gabriel", image_size='(7 3)) :session graphs
#+ATTR_LATEX: :width 1\textwidth
#+RESULTS:
[[file:/home/gabip/perf/gabriel/images/latency_gabriel.png]]



* Relatorio :noexport:
#+CALL plot_download_per_hour(user="gabriel") :session graphs
#+NAME: download_per_hour_gabriel

** Conteudo Latex
:PROPERTIES:
:EXPORT_FILE_NAME: relatorio
:EXPORT_LATEX_CLASS: acmart
:EXPORT_LATEX_CLASS_OPTIONS: [acmsmall]
:EXPORT_LATEX_OPTIONS: body-only:t
:END:

#+LATEX_HEADER: \usepackage{graphicx}
#+LATEX_HEADER: \usepackage{float}
#+LATEX_HEADER: \AtBeginDocument{\providecommand\BibTeX{{Bib\TeX}}}

#+ATTR_LATEX: :exports raw
#+BEGIN_EXPORT latex
%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{ Medição do impacto de uma infraestrutura de VPN na taxa de transmissão e na latência}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Ester Crestani}
\author{Gabriel Pereira}
\author{Julia Pimentel}


%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
%\renewcommand{\shortauthors}{Trovato et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
 Este estudo teve como objetivo avaliar o impacto da infraestrutura de VPN da UFRGS, baseada em OpenVPN, no desempenho de rede. Foram realizadas medições de vazão (throughput), latência, jitter e perda de pacotes em computadores pessoais dos integrantes do grupo, utilizando iperf3, ping e scripts em Python para automatizar as coletas nos cenários com e sem VPN, em diferentes horários do dia. Os resultados mostraram que XXXXX
\end{abstract}


\maketitle


\section{Introdução}
Este trabalho foi desenvolvido na disciplina de Avaliação de Desempenho do curso de Engenharia de Computação da UFRGS, tendo como objetivo aplicar, em um sistema real, os conceitos de medições de desempenho estudados em aula. O objeto de estudo é a infraestrutura de VPN (Virtual Private Network) disponibilizada pela universidade, acessada por meio do protocolo OpenVPN e utilizada pela comunidade acadêmica para acesso remoto seguro a serviços institucionais e recursos restritos à rede interna

As redes privadas virtuais vêm se tornando cada vez mais importantes em ambientes acadêmicos e corporativos, pois adicionam uma camada de criptografia e encapsulamento ao tráfego de dados. No entanto, essa camada extra pode introduzir overhead na comunicação e afetar a qualidade da conexão. Nesse contexto, este trabalho investiga, de forma prática, como o uso de VPN impacta o desempenho de rede, com foco em quatro métricas: vazão (throughput), latência, jitter e perda de pacotes.

Para isso, são realizadas medições diretas dessas métricas em cenários com e sem uso da VPN da UFRGS, em diferentes horários de utilização. Parte-se da hipótese de que a VPN reduz a vazão disponível e aumenta a latência, o jitter e a perda de pacotes, degradando o desempenho percebido pelo usuário. O objetivo é quantificar esse impacto e fornecer uma visão clara sobre os efeitos do uso da VPN em condições reais de operação.


\section{Metodologia}
Nesta seção é apresentada a metodologia utilizada para avaliar o impacto da VPN da UFRGS no desempenho de rede. São descritos o método de análise escolhido, o ambiente de medição, as ferramentas empregadas e o procedimento adotado para a coleta das medições de vazão, latência, jitter e perda de pacotes, em cenários com e sem uso da VPN.


\subsection{ Ambiente de medição}
Os experimentos foram realizados nos computadores pessoais dos integrantes do grupo, conectados à internet residencial, utilizando o cliente OpenVPN e a infraestrutura de VPN disponibilizada pela UFRGS para alunos. Como objeto de estudo, adotou-se essa VPN institucional devido à sua relevância prática no contexto acadêmico e ao fácil acesso pelos participantes.

As medições foram conduzidas em dias e horários distintos, em condições reais de uso, com a VPN conectada e desconectada. Os testes envolveram o acesso a um serviços utilizado rotineiramente pela comunidade acadêmica (moodle), de modo a representar de forma realista o uso típico da VPN e padronizar os experimentos para melhor análise.



\subsection{Ferramentas}

Para avaliar o desempenho da rede no contexto deste estudo, foram utilizadas principalmente as ferramentas iperf3 e ping.
O iperf3 foi empregado para medir a vazão (throughput), utilizando o servidor disponibilizado pelo PCAD da universidade como ponto remoto de teste. Os experimentos foram executados em cenários com e sem VPN, permitindo comparar diretamente o impacto do túnel VPN nessas métricas.

Já o ping foi utilizado para medir a latência (RTT), o jitter (de acordo com o RFC 3550) e a perda de pacotes. Para isso, foram realizados testes sempre tendo como destino a plataforma Moodle da UFRGS, de forma a padronizar os experimentos e permitir uma comparação mais consistente entre os cenários com e sem uso da VPN.

\subsection{Experimentos}

Os experimentos foram realizados a partir de um script em Python desenvolvido especificamente para este trabalho, responsável por executar os testes de desempenho e registrar automaticamente os resultados. O script realiza testes de vazão (throughput) com o iperf3 e testes de latência e perda de pacotes por meio do ping, salvando os dados em arquivos no formato CSV para posterior análise.

Para garantir que o experimento fosse igualitário entre os participantes e pudesse ser reproduzido, o projeto foi organizado em um repositório no GitHub, contendo o código-fonte e um arquivo de requisitos para instalação das dependências. Cada integrante do grupo executou o script em seu próprio computador, utilizando a mesma versão do código e o mesmo conjunto de parâmetros. Os arquivos de dados gerados foram armazenados em pastas separadas por participante, permitindo a análise individual de cada ambiente de teste.

O script também automatiza o controle do estado da VPN da UFRGS. Durante a execução, ele realiza a conexão e a desconexão da VPN de forma programada, alternando entre períodos com a VPN ativa e inativa. Em cada estado, são executadas sequências de testes de iperf3 e ping, mantendo a mesma duração e o mesmo padrão de repetição, de modo a tornar comparáveis os resultados obtidos com e sem o uso da VPN. Além disso, parâmetros como número de ciclos, duração de cada ciclo e tempo total de execução podem ser ajustados no próprio script, o que permite adaptar o experimento ao tempo disponível de coleta sem comprometer a padronização entre os participantes.


\section{Resultados}
Os resultados dos experimentos foram armazenados em arquivos .csv separados para cada integrante do grupo. A partir desses dados, foi desenvolvido um script em Python para gerar gráficos que sintetizam os resultados de cada amostra, por participante. Esses gráficos permitem visualizar de forma comparativa a influência do uso da VPN sobre as métricas de desempenho analisadas: latência, jitter, vazão e perda de pacotes.

Nas seções a seguir, os resultados são apresentados em subtópicos organizados por métrica, acompanhados dos respectivos gráficos, de modo a facilitar a interpretação do impacto da VPN em cada caso.

\subsection {Jitter}
O jitter foi analisado a partir da variação do atraso (RTT) entre pacotes consecutivos, em milissegundos, ao longo do tempo. Em termos práticos, ele representa o quanto a latência oscila de um pacote para o outro, quanto maior o jitter, menos previsível é o atraso, o que pode prejudicar aplicações sensíveis a tempo real, como chamadas de vídeo, VoIP e jogos online.

Para visualizar esse comportamento, optou-se por utilizar gráficos de linha, que permitem acompanhar a evolução do jitter em função do tempo, destacando períodos de maior instabilidade, e gráfico de violino, que resume a distribuição dos valores de jitter, sendo ambos representados por gráficos para cada condição (VPN ligada e desligada). Esse gráfico de violino evidencia não apenas valores médios, mas também a dispersão e a concentração dos dados, facilitando a comparação entre os cenários e a interpretação do impacto da VPN na variabilidade do atraso.
Como resultado, observou-se que XXXXXXXX (analisar gráficos)

% Imagens Jitter comparação  ----------------------------------
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{jitter_comparison_gabriel}
    \caption{Comparação de jitter com e sem VPN para Gabriel}
    \label{fig:jitter_gabriel}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{jitter_comparison_ester}
    \caption{Comparação de jitter com e sem VPN para Gabriel}
    \label{fig:jitter_ester}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{jitter_comparison_julia}
    \caption{Comparação de jitter com e sem VPN para Julia}
    \label{fig:jitter_julia}
\end{figure}

% Imagens Jitter violino  ----------------------------------
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{jitter_comparison_violin_gabriel}
    \caption{Gráfico de violino para jitter com e sem VPN para Gabriel}
    \label{fig:jitter_violino_gabriel}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{jitter_comparison_violin_ester}
    \caption{Gráfico de violino para jitter com e sem VPN para Ester}
    \label{fig:jitter_violino_ester}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{jitter_comparison_violin_julia}
    \caption{Gráfico de violino para jitter com e sem VPN para Gabriel}
    \label{fig:jitter_violino_julia}
\end{figure}

%--------------------------------------

\subsection {Latência}
Para o estudo dos resultados obtidos a partir dos dados de latência, foi feita uma breve análise dessa métrica. A latência corresponde ao tempo que um pacote leva para sair da máquina do usuário, alcançar o destino e retornar (RTT), sendo percebida como o “atraso” entre uma requisição e a resposta do sistema. Valores elevados de latência tendem a impactar negativamente aplicações interativas, como navegação web, acesso remoto e serviços em tempo quase real.

Para analisar esse comportamento, foram utilizadas duas formas principais de visualização. Os gráficos de violino permitem identificar a distribuição dos valores de latência em cada cenário (com e sem VPN), destacando regiões de maior concentração, presença de caudas longas e possíveis outliers. Dessa forma, é possível comparar não apenas valores médios, mas também a variabilidade e a dispersão introduzidas pelo uso da VPN. Já os mapas de calor de latência foram empregados para observar a evolução temporal dessa métrica ao longo do dia, avaliando se a latência apresenta aumento sistemático em determinados períodos, o que poderia estar associado a fatores externos, como maior número de usuários conectados durante horários de aula.

A partir dos dados observados, resultou-se que XXXXX.


% Imagens Mapa de calor de latência  ----------------------------------
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{latency_heatmap_gabriel}
    \caption{Mapa de calor de latência para Gabriel}
    \label{fig:latency_heatmap_gabriel}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{latency_heatmap_ester}
    \caption{Mapa de calor de latência para Ester}
    \label{fig:latency_heatmap_ester}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{latency_heatmap_julia}
    \caption{Mapa de calor de latência para Julia}
    \label{fig:latency_heatmap_julia}
\end{figure}

% Imagens Gráfico de violino latência ----------------------------------
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{latency_violin_gabriel}
    \caption{Gráfico de violino de latência para Gabriel}
    \label{fig:latency_violino_gabriel}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{latency_violin_ester}
    \caption{Gráfico de violino de latência para Ester}
    \label{fig:latency_violino_ester}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{latency_violin_julia}
    \caption{Gráfico de violino de latência para Julia}
    \label{fig:latency_violino_julia}
\end{figure}

%------------------------------------------------------

\subsection {Perda de pacotes}

Para a perda de pacotes, foi analisada a taxa percentual de pacotes perdidos ao longo do período observado. A perda de pacotes representa a proporção de mensagens enviadas que não chegam corretamente ao destino, seja por descarte em algum roteador intermediário, estouro de fila, erros de transmissão ou outros problemas na rede. Em termos práticos, valores mais altos de perda tendem a degradar a experiência do usuário, causando travamentos em vídeos, cortes em chamadas de voz e necessidade de retransmissões em protocolos confiáveis.

Como resultados, observou-se que XXXXX

% Imagens Perda de pacotes + AVG -------------------
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{loss_gabriel_avg}
    \caption{Comparação de perda de pacotes com e sem VPN para Gabriel}
    \label{fig:loss_gabriel_avg}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{loss_ester_avg}
    \caption{Comparação de perda de pacotes com e sem VPN para Ester}
    \label{fig:loss_ester_avg}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{loss_julia_avg}
    \caption{Comparação de perda de pacotes com e sem VPN para Julia}
    \label{fig:loss_julia_avg}
\end{figure}

% ---------------------------------------------------

\subsection {Vazão}
Para a vazão, foram analisados os valores médios de taxa de transmissão obtidos pelo iperf3 ao longo do período de coleta, tanto com a VPN ativada quanto desativada. A vazão (throughput) representa a quantidade de dados efetivamente transmitidos por unidade de tempo entre cliente e servidor, sendo diretamente ligada à rapidez percebida em atividades como download de arquivos, carregamento de páginas e streaming de vídeo.

Para representar esses resultados, foram utilizados gráficos de linha, separando os cenários com e sem VPN. Cada ponto do gráfico corresponde à vazão medida em um determinado instante, permitindo observar a evolução da taxa de transmissão ao longo dos dias de experimento, bem como oscilações e possíveis quedas pontuais. A comparação visual entre os dois painéis (com VPN e sem VPN) facilita identificar diferenças globais de nível de vazão e padrões de variação associados ao uso do túnel VPN.

A partir dos dados observados, verificou-se que XXX

% Imagens Vazão com e sem VPN -------------------
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{<<download_per_hour_gabriel>>}
    \caption{Comparação da vazão com e sem VPN para Gabriel.}
    \label{fig:throughput_gabriel}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{throughput_comparison_ester}
    \caption{Comparação da vazão com e sem VPN para Ester.}
    \label{fig:throughput_ester}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{throughput_comparison_julia}
    \caption{Comparação da vazão com e sem VPN para Julia.}
    \label{fig:throughput_julia}
\end{figure}

% --------------------------------------------------------

\section{Conclusão}
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX


\section{ Referências }

\begin{thebibliography}{9}


\bibitem{jain1991}
Raj Jain.
\newblock \emph{The Art of Computer Systems Performance Analysis: Techniques for Experimental Design, Measurement, Simulation, and Modeling}.
\newblock John Wiley \& Sons, New York, 1991. ISBN 0471503363.

\bibitem{montgomeryRunger}
Douglas C. Montgomery and George C. Runger.
\newblock \emph{Applied Statistics and Probability for Engineers}.
\newblock 6th edition, Wiley.

\bibitem{rfc3550}
H. Schulzrinne, S. Casner, R. Frederick and V. Jacobson.
\newblock \emph{RTP: A Transport Protocol for Real-Time Applications}.
\newblock RFC 3550 (Standard), 2003.
\newblock Disponível em: \texttt{https://www.rfc-editor.org/rfc/rfc3550}. Acesso em: 30 nov. 2025.

\bibitem{leboudec2010}
Jean-Yves Le Boudec.
\newblock \emph{Performance Evaluation Of Computer And Communication Systems}.
\newblock 2010. ISBN 978-2-940222-40-7.
\newblock Disponível em: \texttt{https://leboudec.github.io/perfeval/}. Acesso em: 30 nov. 2025.

\bibitem{rougier2014}
Nicolas P. Rougier, Michael Droettboom and Philip E. Bourne.
\newblock Ten simple rules for better figures.
\newblock \emph{PLOS Computational Biology}, 10(9):e1003833, 2014.
\newblock DOI: \texttt{10.1371/journal.pcbi.1003833}.
\newblock Disponível em: \texttt{https://doi.org/10.1371/journal.pcbi.1003833}. Acesso em: 30 nov. 2025.

\end{thebibliography}
#+END_EXPORT
